{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters and Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_val_ratio = 0.9999\n",
    "\n",
    "epoch = 500\n",
    "batch_size = 16\n",
    "save_best = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_shape, 32),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PATH\n",
    "change path to yours"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "MODEL_PATH = './models/model.pt'\n",
    "TRAIN_PATH = './train.csv'\n",
    "TEST_PATH = './test.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data\n",
    "load data and filled missing value with mean / drop [`id`] [`product_code`]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{TRAIN_PATH}')\n",
    "test_df = pd.read_csv(f'{TEST_PATH}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Replace str by int using LabelEncoder\n",
    "    data_le = copy.deepcopy(data)\n",
    "\n",
    "    cols = ['attribute_0', 'attribute_1']\n",
    "    for col in cols:\n",
    "        data_le[col] = le.fit_transform(data_le[col])\n",
    "\n",
    "    data_le = data_le.drop(['id', 'product_code'], axis=1)\n",
    "\n",
    "    # filled missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    final_data = pd.DataFrame(imputer.fit_transform(data_le))\n",
    "\n",
    "    final_data.columns = data_le.columns\n",
    "\n",
    "    return final_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   loading  attribute_0  attribute_1  attribute_2  attribute_3  measurement_0  \\\n0    80.10          1.0          2.0          9.0          5.0            7.0   \n1    84.89          1.0          2.0          9.0          5.0           14.0   \n2    82.43          1.0          2.0          9.0          5.0           12.0   \n3   101.07          1.0          2.0          9.0          5.0           13.0   \n4   188.06          1.0          2.0          9.0          5.0            9.0   \n\n   measurement_1  measurement_2  measurement_3  measurement_4  ...  \\\n0            8.0            4.0         18.040         12.518  ...   \n1            3.0            3.0         18.213         11.540  ...   \n2            1.0            5.0         18.057         11.652  ...   \n3            2.0            6.0         17.295         11.188  ...   \n4            2.0            8.0         19.346         12.950  ...   \n\n   measurement_9  measurement_10  measurement_11  measurement_12  \\\n0         10.672          15.859       17.594000          15.193   \n1         12.448          17.947       17.915000          11.755   \n2         12.715          15.607       19.172085          13.798   \n3         12.471          16.346       18.377000          10.020   \n4         10.337          17.082       19.932000          12.428   \n\n   measurement_13  measurement_14  measurement_15  measurement_16  \\\n0          15.029       16.048444          13.034          14.684   \n1          14.732       15.425000          14.395          15.631   \n2          16.711       18.631000          14.094          17.946   \n3          15.250       15.562000          16.154          17.172   \n4          16.182       12.760000          13.153          16.412   \n\n   measurement_17  failure  \n0         764.100      0.0  \n1         682.057      0.0  \n2         663.376      0.0  \n3         826.282      0.0  \n4         579.885      0.0  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loading</th>\n      <th>attribute_0</th>\n      <th>attribute_1</th>\n      <th>attribute_2</th>\n      <th>attribute_3</th>\n      <th>measurement_0</th>\n      <th>measurement_1</th>\n      <th>measurement_2</th>\n      <th>measurement_3</th>\n      <th>measurement_4</th>\n      <th>...</th>\n      <th>measurement_9</th>\n      <th>measurement_10</th>\n      <th>measurement_11</th>\n      <th>measurement_12</th>\n      <th>measurement_13</th>\n      <th>measurement_14</th>\n      <th>measurement_15</th>\n      <th>measurement_16</th>\n      <th>measurement_17</th>\n      <th>failure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>80.10</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n      <td>18.040</td>\n      <td>12.518</td>\n      <td>...</td>\n      <td>10.672</td>\n      <td>15.859</td>\n      <td>17.594000</td>\n      <td>15.193</td>\n      <td>15.029</td>\n      <td>16.048444</td>\n      <td>13.034</td>\n      <td>14.684</td>\n      <td>764.100</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>84.89</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>18.213</td>\n      <td>11.540</td>\n      <td>...</td>\n      <td>12.448</td>\n      <td>17.947</td>\n      <td>17.915000</td>\n      <td>11.755</td>\n      <td>14.732</td>\n      <td>15.425000</td>\n      <td>14.395</td>\n      <td>15.631</td>\n      <td>682.057</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>82.43</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>12.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>18.057</td>\n      <td>11.652</td>\n      <td>...</td>\n      <td>12.715</td>\n      <td>15.607</td>\n      <td>19.172085</td>\n      <td>13.798</td>\n      <td>16.711</td>\n      <td>18.631000</td>\n      <td>14.094</td>\n      <td>17.946</td>\n      <td>663.376</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>101.07</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>17.295</td>\n      <td>11.188</td>\n      <td>...</td>\n      <td>12.471</td>\n      <td>16.346</td>\n      <td>18.377000</td>\n      <td>10.020</td>\n      <td>15.250</td>\n      <td>15.562000</td>\n      <td>16.154</td>\n      <td>17.172</td>\n      <td>826.282</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>188.06</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>19.346</td>\n      <td>12.950</td>\n      <td>...</td>\n      <td>10.337</td>\n      <td>17.082</td>\n      <td>19.932000</td>\n      <td>12.428</td>\n      <td>16.182</td>\n      <td>12.760000</td>\n      <td>13.153</td>\n      <td>16.412</td>\n      <td>579.885</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 24 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = clean(train_df)\n",
    "test_df_clean = clean(test_df)\n",
    "\n",
    "train_df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare train data\n",
    "split train data to train and val\n",
    "use dataloader to load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, data, return_y=True):\n",
    "        self.data = data\n",
    "        self.return_y = return_y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.return_y == True:\n",
    "            x = self.data[index][:-1]\n",
    "            y = self.data[index][-1]\n",
    "            return torch.FloatTensor(x), torch.FloatTensor(torch.from_numpy(np.array(y, dtype=np.float32)))\n",
    "        else:\n",
    "            x = self.data[index]\n",
    "            return torch.FloatTensor(x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "data_ds = {}\n",
    "train_np = train_df.to_numpy()\n",
    "\n",
    "train_data, val_data = train_test_split(train_df, train_size=train_val_ratio)\n",
    "\n",
    "data_ds['train'] = TaskDataset(np.array(train_data))\n",
    "data_ds['val'] = TaskDataset(np.array(val_data))\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        data_ds[x],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True) for x in [\n",
    "        'train',\n",
    "        'val']}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 26567, 'val': 3}\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {x: len(data_ds[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Model\n",
    "**Model**: input_shape -> 32 -> 64 -> 1\n",
    "**optimizer**: Adam( lr=0.001, betas=( 0.9, 0.999), eps=1e-08 )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_accuracy = []\n",
    "train_loss = []\n",
    "val_accuracy = []\n",
    "val_loss = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def calculate_acc(y_pred, y_test):\n",
    "    y_pred = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred == y_test).sum().float()\n",
    "    acc = correct_results_sum / y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model,\n",
    "        criterion,\n",
    "        dataloaders,\n",
    "        optimizer,\n",
    "        num_epochs=25,\n",
    "        enable_tqdm=False):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    min_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        # print('-' * 10)\n",
    "        epoch_since = time.time()\n",
    "        loss_history = []\n",
    "        acc_history = []\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            # Iterate over data.\n",
    "            if enable_tqdm:\n",
    "                t = tqdm(enumerate(dataloaders[phase]), total=len(dataloaders[phase]))\n",
    "            else:\n",
    "                t = enumerate(dataloaders[phase])\n",
    "            for i, (x_train, y_train) in t:\n",
    "                x_train = x_train.to(device)\n",
    "                y_train = y_train.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    y_pred = model(x_train)\n",
    "                    y_train = y_train.unsqueeze(-1)\n",
    "                    loss = criterion(y_pred, y_train)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_train_acc = calculate_acc(y_pred, y_train).item()\n",
    "                acc_history.append(running_train_acc)\n",
    "                loss_history.append(loss.item())\n",
    "                # tqdm settings\n",
    "                if enable_tqdm:\n",
    "                    # epoch_loss = torch.mean(torch.Tensor(loss_history)).item()\n",
    "                    # epoch_acc = torch.mean(torch.Tensor(acc_history)).item()\n",
    "                    t.set_description(f'epoch_{epoch}/{num_epochs} {phase}\\t')\n",
    "                    # t.set_description(f'epoch_{epoch} {phase}  \\t**Acc={epoch_acc/100:.4f}**  Loss={epoch_loss:.4f}')\n",
    "\n",
    "            epoch_loss = torch.mean(torch.Tensor(loss_history)).item()\n",
    "            epoch_acc = torch.mean(torch.Tensor(acc_history)).item() / 100\n",
    "            if epoch % 10 == 0 and enable_tqdm == False:\n",
    "                print(f'epoch_{epoch} {phase} Loss: {epoch_loss:.7f} Acc: {epoch_acc:.4f}')\n",
    "            elif enable_tqdm:\n",
    "                clear_output(wait=True)\n",
    "\n",
    "            # loop.set_description(f'Epoch [{epoch}/{num_epoch}]')\n",
    "            # loop.set_postfix(loss=loss.item(), acc=running_train_acc)\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                min_loss = epoch_loss\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            # record loss and accuracy\n",
    "            if phase == 'train':\n",
    "                train_accuracy.append(float(epoch_acc))\n",
    "                train_loss.append(float(epoch_loss))\n",
    "            elif phase == 'val':\n",
    "                val_accuracy.append(float(epoch_acc))\n",
    "                val_loss.append(float(epoch_loss))\n",
    "\n",
    "        epoch_time_elapsed = time.time() - epoch_since\n",
    "        # tqdm.write(\n",
    "        #     f'Time elapsed {epoch_time_elapsed // 60:.0f}m {epoch_time_elapsed % 60:.0f}s\\n')\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    tqdm.write(\n",
    "        f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    tqdm.write(f'Best val Acc: {best_acc:4f} Best epoch: {best_epoch}')\n",
    "\n",
    "    # load best model weights\n",
    "    if save_best:\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    torch.save(model, f'{MODEL_PATH}')\n",
    "    return model, best_epoch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "{'': Model(\n   (layers): Sequential(\n     (0): Linear(in_features=23, out_features=32, bias=True)\n     (1): ELU(alpha=1.0)\n     (2): Linear(in_features=32, out_features=64, bias=True)\n     (3): ELU(alpha=1.0)\n     (4): Linear(in_features=64, out_features=1, bias=True)\n   )\n ),\n 'layers': Sequential(\n   (0): Linear(in_features=23, out_features=32, bias=True)\n   (1): ELU(alpha=1.0)\n   (2): Linear(in_features=32, out_features=64, bias=True)\n   (3): ELU(alpha=1.0)\n   (4): Linear(in_features=64, out_features=1, bias=True)\n ),\n 'layers.0': Linear(in_features=23, out_features=32, bias=True),\n 'layers.1': ELU(alpha=1.0),\n 'layers.2': Linear(in_features=32, out_features=64, bias=True),\n 'layers.3': ELU(alpha=1.0),\n 'layers.4': Linear(in_features=64, out_features=1, bias=True)}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(input_shape=train_np.shape[1] - 1)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.001,\n",
    "    betas=(\n",
    "        0.9,\n",
    "        0.999),\n",
    "    eps=1e-08)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "dict(model.named_modules())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0 train Loss: 0.5575756 Acc: 0.7799\n",
      "epoch_0 val Loss: 0.5573665 Acc: 0.7800\n",
      "epoch_10 train Loss: 0.5107872 Acc: 0.7876\n",
      "epoch_10 val Loss: 0.5106018 Acc: 0.7877\n",
      "epoch_20 train Loss: 0.5099689 Acc: 0.7879\n",
      "epoch_20 val Loss: 0.5098037 Acc: 0.7880\n",
      "epoch_30 train Loss: 0.5099548 Acc: 0.7880\n",
      "epoch_30 val Loss: 0.5097943 Acc: 0.7881\n",
      "epoch_40 train Loss: 0.5104989 Acc: 0.7875\n",
      "epoch_40 val Loss: 0.5103312 Acc: 0.7876\n",
      "epoch_50 train Loss: 0.5099977 Acc: 0.7879\n",
      "epoch_50 val Loss: 0.5098285 Acc: 0.7880\n",
      "epoch_60 train Loss: 0.5098612 Acc: 0.7875\n",
      "epoch_60 val Loss: 0.5096841 Acc: 0.7876\n",
      "epoch_70 train Loss: 0.5100456 Acc: 0.7877\n",
      "epoch_70 val Loss: 0.5098632 Acc: 0.7879\n",
      "epoch_80 train Loss: 0.5096288 Acc: 0.7880\n",
      "epoch_80 val Loss: 0.5094877 Acc: 0.7881\n",
      "epoch_90 train Loss: 0.5098630 Acc: 0.7876\n",
      "epoch_90 val Loss: 0.5096930 Acc: 0.7877\n",
      "epoch_100 train Loss: 0.5098044 Acc: 0.7877\n",
      "epoch_100 val Loss: 0.5096220 Acc: 0.7878\n",
      "epoch_110 train Loss: 0.5097315 Acc: 0.7878\n",
      "epoch_110 val Loss: 0.5095559 Acc: 0.7879\n",
      "epoch_120 train Loss: 0.5095968 Acc: 0.7877\n",
      "epoch_120 val Loss: 0.5094243 Acc: 0.7879\n",
      "epoch_130 train Loss: 0.5095803 Acc: 0.7878\n",
      "epoch_130 val Loss: 0.5094100 Acc: 0.7880\n",
      "epoch_140 train Loss: 0.5102493 Acc: 0.7877\n",
      "epoch_140 val Loss: 0.5100959 Acc: 0.7879\n",
      "epoch_150 train Loss: 0.5098450 Acc: 0.7879\n",
      "epoch_150 val Loss: 0.5096401 Acc: 0.7880\n"
     ]
    }
   ],
   "source": [
    "model, best_epoch = train_model(\n",
    "    model,\n",
    "    criterion,\n",
    "    dataloaders,\n",
    "    optimizer,\n",
    "    num_epochs=epoch,\n",
    "    enable_tqdm=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#printing the loss\n",
    "plt.plot(val_loss)\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#printing the accuracy\n",
    "plt.plot(val_accuracy)\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data = test_df_clean.to_numpy()\n",
    "test_ds = TaskDataset(test_data, return_y=False)\n",
    "print(\"test num: \", test_ds.__len__())\n",
    "test_dl = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=10,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "pred = []\n",
    "for x in tqdm(test_dl):\n",
    "    x = x.to(device)\n",
    "    y_pred = model(x)\n",
    "    output = torch.sigmoid(y_pred)\n",
    "    output = output.cpu().detach().numpy()\n",
    "    pred.append(output[:][0])\n",
    "    # for i in range(len(output)):\n",
    "    #     pred.append(output[i][0])\n",
    "result = pd.DataFrame({'id': test_df['id'], 'failure': pred})\n",
    "result.to_csv('submission.csv', index=False)\n",
    "result\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "process_time = time.time() - start_time\n",
    "print(\n",
    "    f'\\n###############################\\n'\n",
    "    f'Process complete in {process_time // 60:.0f}m {process_time % 60:.0f}s')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
